{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Prepare Datasets\n",
    "\n",
    "This notebook prepares the datasets for the Format Matters project.\n",
    "\n",
    "**Datasets:**\n",
    "1. **CIFAR-10** (small): Auto-download with torchvision\n",
    "2. **ImageNet-mini** (medium, preferred): Manual upload/download\n",
    "3. **Tiny-ImageNet-200** (medium, fallback): Auto-download\n",
    "\n",
    "**Output:**\n",
    "- Datasets extracted to `data/raw/<dataset>/`\n",
    "- Verification of dataset integrity\n",
    "- Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Common utilities loaded successfully\n",
      "\n",
      "Available functions:\n",
      "  - set_seed(seed)\n",
      "  - get_transforms(augment)\n",
      "  - write_sysinfo(path)\n",
      "  - time_first_batch(dataloader, device)\n",
      "  - start_monitor(log_path, interval)\n",
      "  - stop_monitor(thread, stop_event)\n",
      "  - append_to_summary(path, row_dict)\n",
      "  - compute_metrics_from_logs(log_path)\n",
      "  - get_device()\n",
      "  - format_bytes(bytes)\n",
      "  - count_parameters(model)\n",
      "\n",
      "Constants:\n",
      "  - STANDARD_TRANSFORM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tarfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import urllib.request\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load common utilities\n",
    "%run ./10_common_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local\n",
      "Base directory: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\n",
      "Data directory: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\n"
     ]
    }
   ],
   "source": [
    "# Detect environment (local vs Kaggle)\n",
    "IS_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    BASE_DIR = Path('/kaggle/working/format-matters')\n",
    "    INPUT_DIR = Path('/kaggle/input')  # For Kaggle datasets\n",
    "else:\n",
    "    BASE_DIR = Path('..').resolve()\n",
    "    INPUT_DIR = None\n",
    "\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "\n",
    "print(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# Create directories\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CIFAR-10 (Small Dataset)\n",
    "\n",
    "Download and extract CIFAR-10 to individual image files for format builders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:11<00:00, 15.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracting train split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dc080a7d014f06b8fb56d4d981243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracting val split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d4d179ffc348eabad926a8f1f87876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ CIFAR-10 prepared:\n",
      "  Train: 50,000 images\n",
      "  Val: 10,000 images\n",
      "  Location: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n"
     ]
    }
   ],
   "source": [
    "def prepare_cifar10():\n",
    "    \"\"\"\n",
    "    Download CIFAR-10 and extract to individual image files.\n",
    "    \"\"\"\n",
    "    cifar_dir = RAW_DIR / 'cifar10'\n",
    "    cifar_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"Downloading CIFAR-10...\")\n",
    "    \n",
    "    # Download using torchvision\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=str(cifar_dir / 'torchvision'),\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root=str(cifar_dir / 'torchvision'),\n",
    "        train=False,\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    # Class names\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    # Extract to individual files\n",
    "    for split_name, dataset in [('train', train_dataset), ('val', test_dataset)]:\n",
    "        split_dir = cifar_dir / split_name\n",
    "        \n",
    "        # Skip if already extracted\n",
    "        if split_dir.exists() and len(list(split_dir.rglob('*.png'))) > 0:\n",
    "            print(f\"  {split_name} already extracted\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Extracting {split_name} split...\")\n",
    "        \n",
    "        for class_idx in range(10):\n",
    "            class_dir = split_dir / class_names[class_idx]\n",
    "            class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save images\n",
    "        for idx, (img, label) in enumerate(tqdm(dataset, desc=f\"  {split_name}\")):\n",
    "            class_name = class_names[label]\n",
    "            img_path = split_dir / class_name / f\"{idx:05d}.png\"\n",
    "            img.save(img_path)\n",
    "    \n",
    "    # Verify\n",
    "    train_count = len(list((cifar_dir / 'train').rglob('*.png')))\n",
    "    val_count = len(list((cifar_dir / 'val').rglob('*.png')))\n",
    "    \n",
    "    print(f\"\\n✓ CIFAR-10 prepared:\")\n",
    "    print(f\"  Train: {train_count:,} images\")\n",
    "    print(f\"  Val: {val_count:,} images\")\n",
    "    print(f\"  Location: {cifar_dir}\")\n",
    "    \n",
    "    return train_count, val_count\n",
    "\n",
    "# Run preparation\n",
    "cifar_train, cifar_val = prepare_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ImageNet-mini (Medium Dataset - Preferred)\n",
    "\n",
    "**Manual Setup Required:**\n",
    "\n",
    "### For Local:\n",
    "1. Download ImageNet-mini dataset\n",
    "2. Extract to `data/raw/imagenet-mini/`\n",
    "3. Structure should be:\n",
    "   ```\n",
    "   imagenet-mini/\n",
    "     train/\n",
    "       <class1>/\n",
    "         img1.JPEG\n",
    "         img2.JPEG\n",
    "       <class2>/\n",
    "         ...\n",
    "     val/\n",
    "       <class1>/\n",
    "         ...\n",
    "   ```\n",
    "\n",
    "### For Kaggle:\n",
    "1. Upload ImageNet-mini as a Kaggle Dataset\n",
    "2. Add it to this notebook via \"Add Data\"\n",
    "3. Run the cell below to copy to working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ImageNet-mini already prepared:\n",
      "  Train: 34,745 images\n",
      "  Val: 3,923 images\n",
      "  Location: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n"
     ]
    }
   ],
   "source": [
    "def prepare_imagenet_mini():\n",
    "    \"\"\"\n",
    "    Prepare ImageNet-mini dataset.\n",
    "    \"\"\"\n",
    "    imagenet_dir = RAW_DIR / 'imagenet-mini'\n",
    "    \n",
    "    # Check if already exists\n",
    "    if imagenet_dir.exists() and (imagenet_dir / 'train').exists():\n",
    "        train_count = len(list((imagenet_dir / 'train').rglob('*.JPEG'))) + \\\n",
    "                     len(list((imagenet_dir / 'train').rglob('*.jpg'))) + \\\n",
    "                     len(list((imagenet_dir / 'train').rglob('*.png')))\n",
    "        val_count = len(list((imagenet_dir / 'val').rglob('*.JPEG'))) + \\\n",
    "                   len(list((imagenet_dir / 'val').rglob('*.jpg'))) + \\\n",
    "                   len(list((imagenet_dir / 'val').rglob('*.png')))\n",
    "        \n",
    "        if train_count > 0:\n",
    "            print(f\"✓ ImageNet-mini already prepared:\")\n",
    "            print(f\"  Train: {train_count:,} images\")\n",
    "            print(f\"  Val: {val_count:,} images\")\n",
    "            print(f\"  Location: {imagenet_dir}\")\n",
    "            return train_count, val_count\n",
    "    \n",
    "    # For Kaggle: try to copy from input\n",
    "    if IS_KAGGLE and INPUT_DIR:\n",
    "        # Look for imagenet-mini in input datasets\n",
    "        possible_names = ['imagenet-mini', 'imagenet_mini', 'imagenetmini']\n",
    "        source_dir = None\n",
    "        \n",
    "        for name in possible_names:\n",
    "            candidate = INPUT_DIR / name\n",
    "            if candidate.exists():\n",
    "                source_dir = candidate\n",
    "                break\n",
    "        \n",
    "        if source_dir:\n",
    "            print(f\"Copying ImageNet-mini from {source_dir}...\")\n",
    "            shutil.copytree(source_dir, imagenet_dir, dirs_exist_ok=True)\n",
    "            \n",
    "            train_count = len(list((imagenet_dir / 'train').rglob('*.JPEG')))\n",
    "            val_count = len(list((imagenet_dir / 'val').rglob('*.JPEG')))\n",
    "            \n",
    "            print(f\"\\n✓ ImageNet-mini copied:\")\n",
    "            print(f\"  Train: {train_count:,} images\")\n",
    "            print(f\"  Val: {val_count:,} images\")\n",
    "            return train_count, val_count\n",
    "    \n",
    "    print(\"⚠ ImageNet-mini not found\")\n",
    "    print(\"  Please follow manual setup instructions above\")\n",
    "    return 0, 0\n",
    "\n",
    "# Try to prepare ImageNet-mini\n",
    "imagenet_train, imagenet_val = prepare_imagenet_mini()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tiny-ImageNet-200 (Medium Dataset - Fallback)\n",
    "\n",
    "If ImageNet-mini is not available, use Tiny-ImageNet-200 as fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_file(url, dest_path):\n",
    "#     \"\"\"\n",
    "#     Download file with progress bar.\n",
    "#     \"\"\"\n",
    "#     dest_path = Path(dest_path)\n",
    "#     dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     class DownloadProgressBar(tqdm):\n",
    "#         def update_to(self, b=1, bsize=1, tsize=None):\n",
    "#             if tsize is not None:\n",
    "#                 self.total = tsize\n",
    "#             self.update(b * bsize - self.n)\n",
    "    \n",
    "#     with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=dest_path.name) as t:\n",
    "#         urllib.request.urlretrieve(url, dest_path, reporthook=t.update_to)\n",
    "\n",
    "\n",
    "# def prepare_tiny_imagenet():\n",
    "#     \"\"\"\n",
    "#     Download and prepare Tiny-ImageNet-200 dataset.\n",
    "#     \"\"\"\n",
    "#     tiny_dir = RAW_DIR / 'tiny-imagenet-200'\n",
    "    \n",
    "#     # Check if already exists\n",
    "#     if tiny_dir.exists() and (tiny_dir / 'train').exists():\n",
    "#         train_count = len(list((tiny_dir / 'train').rglob('*.JPEG')))\n",
    "#         val_count = len(list((tiny_dir / 'val').rglob('*.JPEG')))\n",
    "        \n",
    "#         if train_count > 0:\n",
    "#             print(f\"✓ Tiny-ImageNet-200 already prepared:\")\n",
    "#             print(f\"  Train: {train_count:,} images\")\n",
    "#             print(f\"  Val: {val_count:,} images\")\n",
    "#             print(f\"  Location: {tiny_dir}\")\n",
    "#             return train_count, val_count\n",
    "    \n",
    "#     print(\"Downloading Tiny-ImageNet-200...\")\n",
    "    \n",
    "#     # Download\n",
    "#     url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "#     zip_path = RAW_DIR / 'tiny-imagenet-200.zip'\n",
    "    \n",
    "#     if not zip_path.exists():\n",
    "#         download_file(url, zip_path)\n",
    "    \n",
    "#     # Extract\n",
    "#     print(\"Extracting...\")\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(RAW_DIR)\n",
    "    \n",
    "#     # Reorganize validation set (it has a different structure)\n",
    "#     val_dir = tiny_dir / 'val'\n",
    "#     if (val_dir / 'images').exists():\n",
    "#         print(\"Reorganizing validation set...\")\n",
    "        \n",
    "#         # Read val annotations\n",
    "#         val_annotations = {}\n",
    "#         with open(val_dir / 'val_annotations.txt', 'r') as f:\n",
    "#             for line in f:\n",
    "#                 parts = line.strip().split('\\t')\n",
    "#                 if len(parts) >= 2:\n",
    "#                     val_annotations[parts[0]] = parts[1]\n",
    "        \n",
    "#         # Move images to class folders\n",
    "#         images_dir = val_dir / 'images'\n",
    "#         for img_file in images_dir.glob('*.JPEG'):\n",
    "#             if img_file.name in val_annotations:\n",
    "#                 class_name = val_annotations[img_file.name]\n",
    "#                 class_dir = val_dir / class_name\n",
    "#                 class_dir.mkdir(exist_ok=True)\n",
    "#                 shutil.move(str(img_file), str(class_dir / img_file.name))\n",
    "        \n",
    "#         # Remove old images directory\n",
    "#         if images_dir.exists():\n",
    "#             shutil.rmtree(images_dir)\n",
    "    \n",
    "#     # Clean up zip\n",
    "#     if zip_path.exists():\n",
    "#         zip_path.unlink()\n",
    "    \n",
    "#     # Count images\n",
    "#     train_count = len(list((tiny_dir / 'train').rglob('*.JPEG')))\n",
    "#     val_count = len(list((tiny_dir / 'val').rglob('*.JPEG')))\n",
    "    \n",
    "#     print(f\"\\n✓ Tiny-ImageNet-200 prepared:\")\n",
    "#     print(f\"  Train: {train_count:,} images\")\n",
    "#     print(f\"  Val: {val_count:,} images\")\n",
    "#     print(f\"  Location: {tiny_dir}\")\n",
    "    \n",
    "#     return train_count, val_count\n",
    "\n",
    "# # Prepare Tiny-ImageNet if ImageNet-mini not available\n",
    "# if imagenet_train == 0:\n",
    "#     print(\"\\nImageNet-mini not available, preparing Tiny-ImageNet-200 as fallback...\\n\")\n",
    "#     tiny_train, tiny_val = prepare_tiny_imagenet()\n",
    "# else:\n",
    "#     print(\"\\nImageNet-mini available, skipping Tiny-ImageNet-200\")\n",
    "#     tiny_train, tiny_val = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "\n",
      "CIFAR-10:\n",
      "  Train: 50,000 images, 10 classes\n",
      "  Val: 10,000 images, 10 classes\n",
      "  Avg size: 32x32\n",
      "\n",
      "ImageNet-mini:\n",
      "  Train: 34,745 images, 1000 classes\n",
      "  Val: 3,923 images, 1000 classes\n",
      "  Avg size: 494x378\n",
      "\n",
      "============================================================\n",
      "\n",
      "✓ 2 dataset(s) prepared and ready for format building\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset(dataset_path: Path, name: str):\n",
    "    \"\"\"\n",
    "    Analyze dataset structure and statistics.\n",
    "    \"\"\"\n",
    "    if not dataset_path.exists():\n",
    "        return None\n",
    "    \n",
    "    stats = {\n",
    "        'name': name,\n",
    "        'path': str(dataset_path),\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = dataset_path / split\n",
    "        if not split_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # Count images\n",
    "        image_files = list(split_dir.rglob('*.JPEG')) + \\\n",
    "                     list(split_dir.rglob('*.jpg')) + \\\n",
    "                     list(split_dir.rglob('*.png'))\n",
    "        \n",
    "        # Count classes\n",
    "        classes = set()\n",
    "        for img_path in image_files:\n",
    "            classes.add(img_path.parent.name)\n",
    "        \n",
    "        # Sample image sizes\n",
    "        sizes = []\n",
    "        for img_path in image_files[:100]:  # Sample first 100\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    sizes.append(img.size)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        stats[f'{split}_images'] = len(image_files)\n",
    "        stats[f'{split}_classes'] = len(classes)\n",
    "        if sizes:\n",
    "            avg_width = sum(s[0] for s in sizes) / len(sizes)\n",
    "            avg_height = sum(s[1] for s in sizes) / len(sizes)\n",
    "            stats[f'{split}_avg_size'] = f\"{avg_width:.0f}x{avg_height:.0f}\"\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "datasets_info = []\n",
    "\n",
    "# CIFAR-10\n",
    "cifar_stats = analyze_dataset(RAW_DIR / 'cifar10', 'CIFAR-10')\n",
    "if cifar_stats:\n",
    "    datasets_info.append(cifar_stats)\n",
    "    print(f\"CIFAR-10:\")\n",
    "    print(f\"  Train: {cifar_stats.get('train_images', 0):,} images, {cifar_stats.get('train_classes', 0)} classes\")\n",
    "    print(f\"  Val: {cifar_stats.get('val_images', 0):,} images, {cifar_stats.get('val_classes', 0)} classes\")\n",
    "    print(f\"  Avg size: {cifar_stats.get('train_avg_size', 'N/A')}\")\n",
    "    print()\n",
    "\n",
    "# ImageNet-mini\n",
    "imagenet_stats = analyze_dataset(RAW_DIR / 'imagenet-mini', 'ImageNet-mini')\n",
    "if imagenet_stats and imagenet_stats.get('train_images', 0) > 0:\n",
    "    datasets_info.append(imagenet_stats)\n",
    "    print(f\"ImageNet-mini:\")\n",
    "    print(f\"  Train: {imagenet_stats.get('train_images', 0):,} images, {imagenet_stats.get('train_classes', 0)} classes\")\n",
    "    print(f\"  Val: {imagenet_stats.get('val_images', 0):,} images, {imagenet_stats.get('val_classes', 0)} classes\")\n",
    "    print(f\"  Avg size: {imagenet_stats.get('train_avg_size', 'N/A')}\")\n",
    "    print()\n",
    "\n",
    "# Tiny-ImageNet-200\n",
    "# tiny_stats = analyze_dataset(RAW_DIR / 'tiny-imagenet-200', 'Tiny-ImageNet-200')\n",
    "# if tiny_stats and tiny_stats.get('train_images', 0) > 0:\n",
    "#     datasets_info.append(tiny_stats)\n",
    "#     print(f\"Tiny-ImageNet-200:\")\n",
    "#     print(f\"  Train: {tiny_stats.get('train_images', 0):,} images, {tiny_stats.get('train_classes', 0)} classes\")\n",
    "#     print(f\"  Val: {tiny_stats.get('val_images', 0):,} images, {tiny_stats.get('val_classes', 0)} classes\")\n",
    "#     print(f\"  Avg size: {tiny_stats.get('train_avg_size', 'N/A')}\")\n",
    "#     print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✓ {len(datasets_info)} dataset(s) prepared and ready for format building\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Acceptance Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running acceptance checks...\n",
      "\n",
      "✓ CIFAR-10: Correct image counts\n",
      "✓ Medium dataset: Available with ≥30k training images\n",
      "✓ Directory structure: All required directories exist\n",
      "\n",
      "============================================================\n",
      "Acceptance checks: 3/3 passed\n",
      "============================================================\n",
      "\n",
      "✅ All checks passed! Ready to proceed with format building.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning acceptance checks...\\n\")\n",
    "\n",
    "checks_passed = 0\n",
    "checks_total = 0\n",
    "\n",
    "# Check 1: CIFAR-10 exists and has correct counts\n",
    "checks_total += 1\n",
    "if cifar_train >= 50000 and cifar_val >= 10000:\n",
    "    print(\"✓ CIFAR-10: Correct image counts\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"✗ CIFAR-10: Expected ≥50k train, ≥10k val, got {cifar_train}, {cifar_val}\")\n",
    "\n",
    "# Check 2: At least one medium dataset available\n",
    "checks_total += 1\n",
    "medium_available = (imagenet_train >= 30000) #or (tiny_train >= 50000)\n",
    "if medium_available:\n",
    "    print(\"✓ Medium dataset: Available with ≥30k training images\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(\"✗ Medium dataset: No dataset with ≥30k training images found\")\n",
    "\n",
    "# Check 3: Directory structure\n",
    "checks_total += 1\n",
    "required_dirs = [\n",
    "    RAW_DIR / 'cifar10/train',\n",
    "    RAW_DIR / 'cifar10/val',\n",
    "]\n",
    "all_dirs_exist = all(d.exists() for d in required_dirs)\n",
    "if all_dirs_exist:\n",
    "    print(\"✓ Directory structure: All required directories exist\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(\"✗ Directory structure: Some required directories missing\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Acceptance checks: {checks_passed}/{checks_total} passed\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if checks_passed == checks_total:\n",
    "    print(\"\\n✅ All checks passed! Ready to proceed with format building.\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some checks failed. Please review and fix issues before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Dataset Preparation Complete\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run format builder notebooks (02-05) to convert datasets\n",
    "2. Each builder will read from `data/raw/<dataset>/`\n",
    "3. Converted formats will be written to `data/built/<dataset>/<format>/`\n",
    "\n",
    "**Available Datasets:**\n",
    "- CIFAR-10 (small, always available)\n",
    "- ImageNet-mini or Tiny-ImageNet-200 (medium, for realistic experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

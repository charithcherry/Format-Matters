{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Build WebDataset (TAR Shards)\n",
    "\n",
    "This notebook creates WebDataset format with TAR-based shards.\n",
    "\n",
    "**Format:** TAR archives with optional compression\n",
    "- Sequential I/O friendly\n",
    "- Configurable shard sizes\n",
    "- Optional zstd compression\n",
    "- Efficient for streaming from object storage\n",
    "\n",
    "**Variants:**\n",
    "- Shard sizes: 64MB, 256MB, 1024MB\n",
    "- Compression: none, zstd\n",
    "\n",
    "**Output:**\n",
    "- `data/built/<dataset>/webdataset/<variant>/*.tar[.zst]`\n",
    "- Build statistics logged to `runs/<session>/summary.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Common utilities loaded successfully\n",
      "\n",
      "Available functions:\n",
      "  - set_seed(seed)\n",
      "  - get_transforms(augment)\n",
      "  - write_sysinfo(path)\n",
      "  - time_first_batch(dataloader, device)\n",
      "  - start_monitor(log_path, interval)\n",
      "  - stop_monitor(thread, stop_event)\n",
      "  - append_to_summary(path, row_dict)\n",
      "  - compute_metrics_from_logs(log_path)\n",
      "  - get_device()\n",
      "  - format_bytes(bytes)\n",
      "  - count_parameters(model)\n",
      "\n",
      "Constants:\n",
      "  - STANDARD_TRANSFORM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import tarfile\n",
    "import io\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import webdataset as wds\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load common utilities\n",
    "%run ./10_common_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local\n",
      "Base directory: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\n",
      "Run directory: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\runs\\20251127-133730\\builds\n",
      "Summary log: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\runs\\20251127-133730\\builds\\summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Detect environment\n",
    "IS_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "BASE_DIR = Path('/kaggle/working/format-matters') if IS_KAGGLE else Path('..').resolve()\n",
    "\n",
    "RAW_DIR = BASE_DIR / 'data/raw'\n",
    "BUILT_DIR = BASE_DIR / 'data/built'\n",
    "\n",
    "# Create run directory for this session\n",
    "RUN_DIR = BASE_DIR / 'runs' / time.strftime('%Y%m%d-%H%M%S') / 'builds'\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_CSV = RUN_DIR / 'summary.csv'\n",
    "SUMMARY_CSV.touch(exist_ok=True)\n",
    "\n",
    "print(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Run directory: {RUN_DIR}\")\n",
    "print(f\"Summary log: {SUMMARY_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Configuration\n",
    "\n",
    "Configure which variants to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will build 6 variants:\n",
      "  - shard64_none\n",
      "  - shard64_zstd\n",
      "  - shard256_none\n",
      "  - shard256_zstd\n",
      "  - shard1024_none\n",
      "  - shard1024_zstd\n"
     ]
    }
   ],
   "source": [
    "# Shard sizes in MB\n",
    "SHARD_SIZES = [64, 256, 1024]\n",
    "\n",
    "# Compression options\n",
    "COMPRESSIONS = ['none', 'zstd']\n",
    "\n",
    "# Generate all variants\n",
    "VARIANTS = []\n",
    "for shard_mb in SHARD_SIZES:\n",
    "    for compression in COMPRESSIONS:\n",
    "        VARIANTS.append({\n",
    "            'shard_mb': shard_mb,\n",
    "            'compression': compression,\n",
    "            'name': f\"shard{shard_mb}_{compression}\"\n",
    "        })\n",
    "\n",
    "print(f\"Will build {len(VARIANTS)} variants:\")\n",
    "for v in VARIANTS:\n",
    "    print(f\"  - {v['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebDataset Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_webdataset_split(\n",
    "    dataset_name: str,\n",
    "    split: str,\n",
    "    raw_path: Path,\n",
    "    output_path: Path,\n",
    "    shard_mb: int,\n",
    "    compression: str,\n",
    "    class_to_label: dict,\n",
    "    image_extensions: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Build WebDataset shards for a single split.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: Name of dataset\n",
    "        split: Split name ('train' or 'val')\n",
    "        raw_path: Path to raw dataset split directory\n",
    "        output_path: Path to output directory\n",
    "        shard_mb: Target shard size in MB\n",
    "        compression: Compression type ('none' or 'zstd')\n",
    "        class_to_label: Mapping from class name to label index\n",
    "        image_extensions: List of image file extensions to include\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with build statistics\n",
    "    \"\"\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(raw_path.rglob(f'*{ext}'))\n",
    "    \n",
    "    # Sort for reproducibility\n",
    "    image_files = sorted(image_files)\n",
    "    split_class_count = len({f.parent.name for f in image_files})\n",
    "    print(f\"    Found {len(image_files):,} images in {split_class_count} classes\")\n",
    "    \n",
    "    # Determine shard pattern\n",
    "    shard_pattern = \"file://\" + (output_path / f\"{split}-%06d.tar\").as_posix()\n",
    "    if compression == 'zstd':\n",
    "        shard_pattern += '.zst'\n",
    "    \n",
    "    # Target shard size in bytes\n",
    "    maxsize = shard_mb * 1024 * 1024\n",
    "    \n",
    "    # Create WebDataset writer\n",
    "    with wds.ShardWriter(shard_pattern, maxsize=maxsize) as sink:\n",
    "        for idx, img_path in enumerate(tqdm(image_files, desc=f\"    Writing {split}\")):\n",
    "            # Read image\n",
    "            with open(img_path, 'rb') as f:\n",
    "                img_bytes = f.read()\n",
    "            \n",
    "            # Get label\n",
    "            class_name = img_path.parent.name\n",
    "            if class_name not in class_to_label:\n",
    "                raise KeyError(f\"Class {class_name} missing from mapping for split {split}\")\n",
    "            label = class_to_label[class_name]\n",
    "            \n",
    "            # Determine image extension\n",
    "            ext = img_path.suffix.lower().lstrip('.')\n",
    "            if ext == 'jpeg':\n",
    "                ext = 'jpg'\n",
    "            \n",
    "            # Create sample\n",
    "            sample = {\n",
    "                '__key__': f\"{idx:08d}\",\n",
    "                ext: img_bytes,\n",
    "                'cls': str(label).encode('utf-8'),  # Store label as text\n",
    "            }\n",
    "            \n",
    "            sink.write(sample)\n",
    "    \n",
    "    # Count shards and total size\n",
    "\n",
    "\n",
    "    shard_files = list(output_path.glob(f\"{split}-*.tar*\"))\n",
    "    total_bytes = sum(f.stat().st_size for f in shard_files)\n",
    "    \n",
    "    return {\n",
    "        'items': len(image_files),\n",
    "        'bytes_on_disk': total_bytes,\n",
    "        'num_files': len(shard_files),\n",
    "        'avg_file_size': total_bytes // len(shard_files) if shard_files else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "def build_webdataset(\n",
    "    dataset_name: str,\n",
    "    raw_path: Path,\n",
    "    output_path: Path,\n",
    "    shard_mb: int,\n",
    "    compression: str,\n",
    "    variant_name: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Build WebDataset for a dataset with specific configuration.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: Name of dataset\n",
    "        raw_path: Path to raw dataset directory\n",
    "        output_path: Path to output directory\n",
    "        shard_mb: Target shard size in MB\n",
    "        compression: Compression type ('none' or 'zstd')\n",
    "        variant_name: Variant identifier\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with build statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\nBuilding WebDataset for {dataset_name} ({variant_name})...\")\n",
    "    print(f\"  Source: {raw_path}\")\n",
    "    print(f\"  Output: {output_path}\")\n",
    "    print(f\"  Shard size: {shard_mb}MB, Compression: {compression}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # FIXED: Use case-insensitive matching\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    all_class_names = set()\n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = raw_path / split\n",
    "        if not split_dir.exists():\n",
    "            continue\n",
    "        for ext in image_extensions:\n",
    "            for img_path in split_dir.rglob(f'*{ext}'):\n",
    "                all_class_names.add(img_path.parent.name)\n",
    "    class_names = sorted(all_class_names)\n",
    "    class_to_label = {name: idx for idx, name in enumerate(class_names)}\n",
    "    print(f\"  Total classes across splits: {len(class_names)}\")\n",
    "    \n",
    "    # Process each split\n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = raw_path / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"  ⚠ {split} split not found, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  Processing {split} split...\")\n",
    "        \n",
    "        split_stats = build_webdataset_split(\n",
    "            dataset_name, split, split_dir, output_path,\n",
    "            shard_mb, compression, class_to_label, image_extensions\n",
    "        )\n",
    "        \n",
    "        print(f\"    ✓ {split}: {split_stats['num_files']} shards, \"\n",
    "              f\"{format_bytes(split_stats['bytes_on_disk'])}\")\n",
    "        \n",
    "        # Log to summary\n",
    "        build_time = time.time() - start_time\n",
    "        row = {\n",
    "            'stage': 'build',\n",
    "            'dataset': dataset_name,\n",
    "            'format': 'webdataset',\n",
    "            'variant': variant_name,\n",
    "            'split': split,\n",
    "            'items': split_stats['items'],\n",
    "            'bytes_on_disk': split_stats['bytes_on_disk'],\n",
    "            'num_files': split_stats['num_files'],\n",
    "            'avg_file_size': split_stats['avg_file_size'],\n",
    "            'build_wall_s': build_time,\n",
    "        }\n",
    "        append_to_summary(SUMMARY_CSV, row)\n",
    "    \n",
    "    build_time = time.time() - start_time\n",
    "    print(f\"\\n  ✓ Build completed in {build_time:.2f}s\")\n",
    "    \n",
    "    return {'dataset': dataset_name, 'variant': variant_name, 'build_time': build_time}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build WebDatasets for All Datasets and Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 dataset(s): cifar10, imagenet-mini\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Find available datasets\n",
    "available_datasets = []\n",
    "for dataset_name in ['cifar10', 'imagenet-mini']:\n",
    "    dataset_path = RAW_DIR / dataset_name\n",
    "    if dataset_path.exists() and (dataset_path / 'train').exists():\n",
    "        available_datasets.append(dataset_name)\n",
    "\n",
    "print(f\"Found {len(available_datasets)} dataset(s): {', '.join(available_datasets)}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building WebDataset for cifar10 (shard64_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard64_none\n",
      "  Shard size: 64MB, Compression: none\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725e13b9022845a2bd6b316d4cf10e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_none/train-000001.tar 30063 0.1 GB 30063\n",
      "    ✓ train: 2 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1dc6e4d47249e7b8f700824684a5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 51.76s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for cifar10 (shard64_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard64_zstd\n",
      "  Shard size: 64MB, Compression: zstd\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67489554a58246a7bb1ad8a8f40e682a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_zstd/train-000001.tar.zst 30063 0.1 GB 30063\n",
      "    ✓ train: 2 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard64_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74093684e564fdfaf6b9be17c9f6749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 28.56s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for cifar10 (shard256_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard256_none\n",
      "  Shard size: 256MB, Compression: none\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard256_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e498c40a84414aaf1bae023f30dc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ train: 1 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard256_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e0a780694f4a4f80b790a318fc7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 26.95s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for cifar10 (shard256_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard256_zstd\n",
      "  Shard size: 256MB, Compression: zstd\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard256_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde4de7c508343c5bd5a4ce4fc2d34ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ train: 1 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard256_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc2c90c4ef54aa8a7507a321eaf99df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 27.12s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for cifar10 (shard1024_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard1024_none\n",
      "  Shard size: 1024MB, Compression: none\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard1024_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f31e3ce498475781e6af5919a40c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ train: 1 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard1024_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d299fe84764436d97d71a1ba816b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 26.23s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for cifar10 (shard1024_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\cifar10\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\cifar10\\webdataset\\shard1024_zstd\n",
      "  Shard size: 1024MB, Compression: zstd\n",
      "  Total classes across splits: 10\n",
      "\n",
      "  Processing train split...\n",
      "    Found 50,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard1024_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e31308e4ba64ba78091123791de17d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ train: 1 shards, 290.2 MB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 10,000 images in 10 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/cifar10/webdataset/shard1024_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ce829ee9c346c78e25b1f2b453fc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 58.1 MB\n",
      "\n",
      "  ✓ Build completed in 26.34s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard64_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard64_none\n",
      "  Shard size: 64MB, Compression: none\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be2ac24d114fcca9284fd4770e051f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000001.tar 583 0.1 GB 583\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000002.tar 593 0.1 GB 1176\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000003.tar 454 0.1 GB 1630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000004.tar 514 0.1 GB 2144\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000005.tar 582 0.1 GB 2726\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000006.tar 565 0.1 GB 3291\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000007.tar 494 0.1 GB 3785\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000008.tar 526 0.1 GB 4311\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000009.tar 822 0.1 GB 5133\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000010.tar 728 0.1 GB 5861\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000011.tar 715 0.1 GB 6576\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000012.tar 657 0.1 GB 7233\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000013.tar 703 0.1 GB 7936\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000014.tar 635 0.1 GB 8571\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000015.tar 677 0.1 GB 9248\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000016.tar 552 0.1 GB 9800\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000017.tar 524 0.1 GB 10324\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000018.tar 581 0.1 GB 10905\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000019.tar 524 0.1 GB 11429\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000020.tar 586 0.1 GB 12015\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000021.tar 548 0.1 GB 12563\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000022.tar 610 0.1 GB 13173\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000023.tar 663 0.1 GB 13836\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000024.tar 642 0.1 GB 14478\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000025.tar 618 0.1 GB 15096\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000026.tar 672 0.1 GB 15768\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000027.tar 678 0.1 GB 16446\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000028.tar 645 0.1 GB 17091\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000029.tar 655 0.1 GB 17746\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000030.tar 607 0.1 GB 18353\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000031.tar 713 0.1 GB 19066\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000032.tar 534 0.1 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000033.tar 681 0.1 GB 20281\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000034.tar 656 0.1 GB 20937\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000035.tar 735 0.1 GB 21672\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000036.tar 663 0.1 GB 22335\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000037.tar 654 0.1 GB 22989\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000038.tar 751 0.1 GB 23740\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000039.tar 626 0.1 GB 24366\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000040.tar 710 0.1 GB 25076\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000041.tar 586 0.1 GB 25662\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000042.tar 688 0.1 GB 26350\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000043.tar 669 0.1 GB 27019\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000044.tar 627 0.1 GB 27646\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000045.tar 696 0.1 GB 28342\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000046.tar 658 0.1 GB 29000\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000047.tar 691 0.1 GB 29691\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000048.tar 591 0.1 GB 30282\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000049.tar 628 0.1 GB 30910\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000050.tar 739 0.1 GB 31649\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000051.tar 663 0.1 GB 32312\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000052.tar 600 0.1 GB 32912\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000053.tar 543 0.1 GB 33455\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000054.tar 562 0.1 GB 34017\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/train-000055.tar 493 0.1 GB 34510\n",
      "    ✓ train: 56 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c6a88138a54167bfc5ee39aebc9fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000001.tar 458 0.1 GB 458\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000002.tar 518 0.1 GB 976\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000003.tar 521 0.1 GB 1497\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000004.tar 567 0.1 GB 2064\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000005.tar 566 0.1 GB 2630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000006.tar 561 0.1 GB 3191\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_none/val-000007.tar 488 0.1 GB 3679\n",
      "    ✓ val: 8 shards, 494.5 MB\n",
      "\n",
      "  ✓ Build completed in 65.08s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard64_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard64_zstd\n",
      "  Shard size: 64MB, Compression: zstd\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1f4a9db8a491496bab7f4a9f54f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000001.tar.zst 583 0.1 GB 583\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000002.tar.zst 593 0.1 GB 1176\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000003.tar.zst 454 0.1 GB 1630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000004.tar.zst 514 0.1 GB 2144\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000005.tar.zst 582 0.1 GB 2726\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000006.tar.zst 565 0.1 GB 3291\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000007.tar.zst 494 0.1 GB 3785\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000008.tar.zst 526 0.1 GB 4311\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000009.tar.zst 822 0.1 GB 5133\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000010.tar.zst 728 0.1 GB 5861\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000011.tar.zst 715 0.1 GB 6576\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000012.tar.zst 657 0.1 GB 7233\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000013.tar.zst 703 0.1 GB 7936\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000014.tar.zst 635 0.1 GB 8571\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000015.tar.zst 677 0.1 GB 9248\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000016.tar.zst 552 0.1 GB 9800\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000017.tar.zst 524 0.1 GB 10324\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000018.tar.zst 581 0.1 GB 10905\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000019.tar.zst 524 0.1 GB 11429\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000020.tar.zst 586 0.1 GB 12015\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000021.tar.zst 548 0.1 GB 12563\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000022.tar.zst 610 0.1 GB 13173\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000023.tar.zst 663 0.1 GB 13836\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000024.tar.zst 642 0.1 GB 14478\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000025.tar.zst 618 0.1 GB 15096\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000026.tar.zst 672 0.1 GB 15768\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000027.tar.zst 678 0.1 GB 16446\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000028.tar.zst 645 0.1 GB 17091\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000029.tar.zst 655 0.1 GB 17746\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000030.tar.zst 607 0.1 GB 18353\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000031.tar.zst 713 0.1 GB 19066\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000032.tar.zst 534 0.1 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000033.tar.zst 681 0.1 GB 20281\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000034.tar.zst 656 0.1 GB 20937\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000035.tar.zst 735 0.1 GB 21672\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000036.tar.zst 663 0.1 GB 22335\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000037.tar.zst 654 0.1 GB 22989\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000038.tar.zst 751 0.1 GB 23740\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000039.tar.zst 626 0.1 GB 24366\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000040.tar.zst 710 0.1 GB 25076\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000041.tar.zst 586 0.1 GB 25662\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000042.tar.zst 688 0.1 GB 26350\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000043.tar.zst 669 0.1 GB 27019\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000044.tar.zst 627 0.1 GB 27646\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000045.tar.zst 696 0.1 GB 28342\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000046.tar.zst 658 0.1 GB 29000\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000047.tar.zst 691 0.1 GB 29691\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000048.tar.zst 591 0.1 GB 30282\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000049.tar.zst 628 0.1 GB 30910\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000050.tar.zst 739 0.1 GB 31649\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000051.tar.zst 663 0.1 GB 32312\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000052.tar.zst 600 0.1 GB 32912\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000053.tar.zst 543 0.1 GB 33455\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000054.tar.zst 562 0.1 GB 34017\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/train-000055.tar.zst 493 0.1 GB 34510\n",
      "    ✓ train: 56 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a98c5aa95f42d08477dcdb8633ff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000001.tar.zst 458 0.1 GB 458\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000002.tar.zst 518 0.1 GB 976\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000003.tar.zst 521 0.1 GB 1497\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000004.tar.zst 567 0.1 GB 2064\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000005.tar.zst 566 0.1 GB 2630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000006.tar.zst 561 0.1 GB 3191\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard64_zstd/val-000007.tar.zst 488 0.1 GB 3679\n",
      "    ✓ val: 8 shards, 494.5 MB\n",
      "\n",
      "  ✓ Build completed in 60.82s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard256_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard256_none\n",
      "  Shard size: 256MB, Compression: none\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec929fa2484f4a6aacf90cc37f04eb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000001.tar 2141 0.3 GB 2141\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000002.tar 2166 0.3 GB 4307\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000003.tar 2920 0.3 GB 7227\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000004.tar 2565 0.3 GB 9792\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000005.tar 2211 0.3 GB 12003\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000006.tar 2464 0.3 GB 14467\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000007.tar 2606 0.3 GB 17073\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000008.tar 2527 0.3 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000009.tar 2713 0.3 GB 22313\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000010.tar 2729 0.3 GB 25042\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000011.tar 2588 0.3 GB 27630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000012.tar 2619 0.3 GB 30249\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/train-000013.tar 2627 0.3 GB 32876\n",
      "    ✓ train: 14 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bd7611f84e443692040c433e071a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_none/val-000001.tar 2060 0.3 GB 2060\n",
      "    ✓ val: 2 shards, 494.4 MB\n",
      "\n",
      "  ✓ Build completed in 62.47s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard256_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard256_zstd\n",
      "  Shard size: 256MB, Compression: zstd\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a638b265ff7141de82710506cfc04812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000001.tar.zst 2141 0.3 GB 2141\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000002.tar.zst 2166 0.3 GB 4307\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000003.tar.zst 2920 0.3 GB 7227\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000004.tar.zst 2565 0.3 GB 9792\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000005.tar.zst 2211 0.3 GB 12003\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000006.tar.zst 2464 0.3 GB 14467\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000007.tar.zst 2606 0.3 GB 17073\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000008.tar.zst 2527 0.3 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000009.tar.zst 2713 0.3 GB 22313\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000010.tar.zst 2729 0.3 GB 25042\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000011.tar.zst 2588 0.3 GB 27630\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000012.tar.zst 2619 0.3 GB 30249\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/train-000013.tar.zst 2627 0.3 GB 32876\n",
      "    ✓ train: 14 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121024beecc74a648f63cfad6eb47911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard256_zstd/val-000001.tar.zst 2060 0.3 GB 2060\n",
      "    ✓ val: 2 shards, 494.4 MB\n",
      "\n",
      "  ✓ Build completed in 63.55s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard1024_none)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard1024_none\n",
      "  Shard size: 1024MB, Compression: none\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_none/train-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d896f4ef12c4ee4a0647ec0ed413574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_none/train-000001.tar 9790 1.1 GB 9790\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_none/train-000002.tar 9810 1.1 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_none/train-000003.tar 10647 1.1 GB 30247\n",
      "    ✓ train: 4 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_none/val-000000.tar 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90328a4ac140ca973c0233f1e547e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 494.4 MB\n",
      "\n",
      "  ✓ Build completed in 78.74s\n",
      "============================================================\n",
      "\n",
      "Building WebDataset for imagenet-mini (shard1024_zstd)...\n",
      "  Source: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\raw\\imagenet-mini\n",
      "  Output: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\data\\built\\imagenet-mini\\webdataset\\shard1024_zstd\n",
      "  Shard size: 1024MB, Compression: zstd\n",
      "  Total classes across splits: 1000\n",
      "\n",
      "  Processing train split...\n",
      "    Found 34,745 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_zstd/train-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671397dea49644fd83f625eb46a976a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing train:   0%|          | 0/34745 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_zstd/train-000001.tar.zst 9790 1.1 GB 9790\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_zstd/train-000002.tar.zst 9810 1.1 GB 19600\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_zstd/train-000003.tar.zst 10647 1.1 GB 30247\n",
      "    ✓ train: 4 shards, 3.6 GB\n",
      "\n",
      "  Processing val split...\n",
      "    Found 3,923 images in 1000 classes\n",
      "# writing file://C:/Users/arjya/Fall 2025/Systems for ML/Project 1/SML/format-matters/data/built/imagenet-mini/webdataset/shard1024_zstd/val-000000.tar.zst 0 0.0 GB 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3123ceaa1c814e228b1f8bc1e8940e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    Writing val:   0%|          | 0/3923 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ val: 1 shards, 494.4 MB\n",
      "\n",
      "  ✓ Build completed in 88.39s\n",
      "============================================================\n",
      "\n",
      "✓ Built 12 WebDataset variant(s)\n"
     ]
    }
   ],
   "source": [
    "# Build all variants for all datasets\n",
    "build_results = []\n",
    "\n",
    "for dataset_name in available_datasets:\n",
    "    raw_path = RAW_DIR / dataset_name\n",
    "    \n",
    "    for variant in VARIANTS:\n",
    "        output_path = BUILT_DIR / dataset_name / 'webdataset' / variant['name']\n",
    "        \n",
    "        result = build_webdataset(\n",
    "            dataset_name=dataset_name,\n",
    "            raw_path=raw_path,\n",
    "            output_path=output_path,\n",
    "            shard_mb=variant['shard_mb'],\n",
    "            compression=variant['compression'],\n",
    "            variant_name=variant['name']\n",
    "        )\n",
    "        build_results.append(result)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n✓ Built {len(build_results)} WebDataset variant(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying WebDataset shards...\n",
      "\n",
      "cifar10:\n",
      "  ✓ shard64_none:\n",
      "      Train: 2 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "  ✓ shard64_zstd:\n",
      "      Train: 2 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "  ✓ shard256_none:\n",
      "      Train: 1 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "  ✓ shard256_zstd:\n",
      "      Train: 1 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "  ✓ shard1024_none:\n",
      "      Train: 1 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "  ✓ shard1024_zstd:\n",
      "      Train: 1 shards, 290.2 MB\n",
      "      Val: 1 shards, 58.1 MB\n",
      "\n",
      "imagenet-mini:\n",
      "  ✓ shard64_none:\n",
      "      Train: 56 shards, 3.6 GB\n",
      "      Val: 8 shards, 494.5 MB\n",
      "  ✓ shard64_zstd:\n",
      "      Train: 56 shards, 3.6 GB\n",
      "      Val: 8 shards, 494.5 MB\n",
      "  ✓ shard256_none:\n",
      "      Train: 14 shards, 3.6 GB\n",
      "      Val: 2 shards, 494.4 MB\n",
      "  ✓ shard256_zstd:\n",
      "      Train: 14 shards, 3.6 GB\n",
      "      Val: 2 shards, 494.4 MB\n",
      "  ✓ shard1024_none:\n",
      "      Train: 4 shards, 3.6 GB\n",
      "      Val: 1 shards, 494.4 MB\n",
      "  ✓ shard1024_zstd:\n",
      "      Train: 4 shards, 3.6 GB\n",
      "      Val: 1 shards, 494.4 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying WebDataset shards...\\n\")\n",
    "\n",
    "for dataset_name in available_datasets:\n",
    "    print(f\"{dataset_name}:\")\n",
    "    \n",
    "    for variant in VARIANTS:\n",
    "        wds_dir = BUILT_DIR / dataset_name / 'webdataset' / variant['name']\n",
    "        \n",
    "        if not wds_dir.exists():\n",
    "            print(f\"  ✗ {variant['name']}: directory not found\")\n",
    "            continue\n",
    "        \n",
    "        # Count shards\n",
    "        train_shards = list(wds_dir.glob('train-*.tar*'))\n",
    "        val_shards = list(wds_dir.glob('val-*.tar*'))\n",
    "        \n",
    "        if not train_shards:\n",
    "            print(f\"  ✗ {variant['name']}: no train shards found\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate sizes\n",
    "        train_size = sum(f.stat().st_size for f in train_shards)\n",
    "        val_size = sum(f.stat().st_size for f in val_shards)\n",
    "        \n",
    "        print(f\"  ✓ {variant['name']}:\")\n",
    "        print(f\"      Train: {len(train_shards)} shards, {format_bytes(train_size)}\")\n",
    "        print(f\"      Val: {len(val_shards)} shards, {format_bytes(val_size)}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting first shard of cifar10 (shard64_none):\n",
      "\n",
      "Shard: train-000000.tar\n",
      "Size: 173.7 MB\n",
      "\n",
      "First 5 samples:\n",
      "\n",
      "Sample 0:\n",
      "  Keys: ['__key__', '__url__', 'cls', 'png']\n",
      "  __key__: 00000000\n",
      "  Image (png): 2063 bytes\n",
      "  Label: 0\n",
      "\n",
      "Sample 1:\n",
      "  Keys: ['__key__', '__url__', 'cls', 'png']\n",
      "  __key__: 00000001\n",
      "  Image (png): 2169 bytes\n",
      "  Label: 0\n",
      "\n",
      "Sample 2:\n",
      "  Keys: ['__key__', '__url__', 'cls', 'png']\n",
      "  __key__: 00000002\n",
      "  Image (png): 2237 bytes\n",
      "  Label: 0\n",
      "\n",
      "Sample 3:\n",
      "  Keys: ['__key__', '__url__', 'cls', 'png']\n",
      "  __key__: 00000003\n",
      "  Image (png): 2104 bytes\n",
      "  Label: 0\n",
      "\n",
      "Sample 4:\n",
      "  Keys: ['__key__', '__url__', 'cls', 'png']\n",
      "  __key__: 00000004\n",
      "  Image (png): 2181 bytes\n",
      "  Label: 0\n"
     ]
    }
   ],
   "source": [
    "# # Inspect first shard of first dataset/variant\n",
    "# if available_datasets and VARIANTS:\n",
    "#     dataset_name = available_datasets[0]\n",
    "#     variant = VARIANTS[0]\n",
    "#     wds_dir = BUILT_DIR / dataset_name / 'webdataset' / variant['name']\n",
    "    \n",
    "#     train_shards = sorted(wds_dir.glob('train-*.tar*'))\n",
    "#     if train_shards:\n",
    "#         print(f\"Inspecting first shard of {dataset_name} ({variant['name']}):\\n\")\n",
    "#         print(f\"Shard: {train_shards[0].name}\")\n",
    "#         print(f\"Size: {format_bytes(train_shards[0].stat().st_size)}\")\n",
    "        \n",
    "#         # Read first few samples\n",
    "#         print(\"\\nFirst 5 samples:\")\n",
    "#         dataset = wds.WebDataset(str(train_shards[0]))\n",
    "        \n",
    "#         for i, sample in enumerate(dataset):\n",
    "#             if i >= 5:\n",
    "#                 break\n",
    "            \n",
    "#             print(f\"\\nSample {i}:\")\n",
    "#             print(f\"  Keys: {list(sample.keys())}\")\n",
    "#             print(f\"  __key__: {sample.get('__key__', 'N/A')}\")\n",
    "            \n",
    "#             # Check image\n",
    "#             for ext in ['jpg', 'jpeg', 'png']:\n",
    "#                 if ext in sample:\n",
    "#                     img_bytes = sample[ext]\n",
    "#                     print(f\"  Image ({ext}): {len(img_bytes)} bytes\")\n",
    "#                     break\n",
    "            \n",
    "#             # Check label\n",
    "#             if 'cls' in sample:\n",
    "#                 label = sample['cls'].decode('utf-8') if isinstance(sample['cls'], bytes) else sample['cls']\n",
    "#                 print(f\"  Label: {label}\")\n",
    "# Inspect first shard of first dataset/variant\n",
    "if available_datasets and VARIANTS:\n",
    "    dataset_name = available_datasets[0]\n",
    "    variant = VARIANTS[0]\n",
    "    wds_dir = BUILT_DIR / dataset_name / 'webdataset' / variant['name']\n",
    "    \n",
    "    train_shards = sorted(wds_dir.glob('train-*.tar*'))\n",
    "    if train_shards:\n",
    "        print(f\"Inspecting first shard of {dataset_name} ({variant['name']}):\\n\")\n",
    "        print(f\"Shard: {train_shards[0].name}\")\n",
    "        print(f\"Size: {format_bytes(train_shards[0].stat().st_size)}\")\n",
    "        \n",
    "        # Force WebDataset to interpret path as local file (works on Windows + Linux)\n",
    "        shard_path = \"file://\" + train_shards[0].as_posix()\n",
    "\n",
    "        print(\"\\nFirst 5 samples:\")\n",
    "        dataset = wds.WebDataset(shard_path)\n",
    "\n",
    "        for i, sample in enumerate(dataset):\n",
    "            if i >= 5:\n",
    "                break\n",
    "\n",
    "            print(f\"\\nSample {i}:\")\n",
    "            print(f\"  Keys: {list(sample.keys())}\")\n",
    "            print(f\"  __key__: {sample.get('__key__', 'N/A')}\")\n",
    "\n",
    "            for ext in ['jpg', 'jpeg', 'png']:\n",
    "                if ext in sample:\n",
    "                    img_bytes = sample[ext]\n",
    "                    print(f\"  Image ({ext}): {len(img_bytes)} bytes\")\n",
    "                    break\n",
    "\n",
    "            if 'cls' in sample:\n",
    "                label = sample['cls'].decode('utf-8') if isinstance(sample['cls'], bytes) else sample['cls']\n",
    "                print(f\"  Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Build Summary:\n",
      "================================================================================\n",
      "\n",
      "dataset:\n",
      "\n",
      "  variant:\n",
      "    split:\n",
      "      Items: N/A\n",
      "      Shards: N/A\n",
      "      Size: N/A\n",
      "      Avg shard: N/A\n",
      "\n",
      "cifar10:\n",
      "\n",
      "  shard64_none:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 2\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 145.1 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "  shard64_zstd:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 2\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 145.1 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "  shard256_none:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 1\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 290.2 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "  shard256_zstd:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 1\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 290.2 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "  shard1024_none:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 1\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 290.2 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "  shard1024_zstd:\n",
      "    train:\n",
      "      Items: 50,000\n",
      "      Shards: 1\n",
      "      Size: 290.2 MB\n",
      "      Avg shard: 290.2 MB\n",
      "    val:\n",
      "      Items: 10,000\n",
      "      Shards: 1\n",
      "      Size: 58.1 MB\n",
      "      Avg shard: 58.1 MB\n",
      "\n",
      "imagenet-mini:\n",
      "\n",
      "  shard64_none:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 56\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 65.9 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 8\n",
      "      Size: 494.5 MB\n",
      "      Avg shard: 61.8 MB\n",
      "\n",
      "  shard64_zstd:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 56\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 65.9 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 8\n",
      "      Size: 494.5 MB\n",
      "      Avg shard: 61.8 MB\n",
      "\n",
      "  shard256_none:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 14\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 263.7 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 2\n",
      "      Size: 494.4 MB\n",
      "      Avg shard: 247.2 MB\n",
      "\n",
      "  shard256_zstd:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 14\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 263.7 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 2\n",
      "      Size: 494.4 MB\n",
      "      Avg shard: 247.2 MB\n",
      "\n",
      "  shard1024_none:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 4\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 923.0 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 1\n",
      "      Size: 494.4 MB\n",
      "      Avg shard: 494.4 MB\n",
      "\n",
      "  shard1024_zstd:\n",
      "    train:\n",
      "      Items: 34,745\n",
      "      Shards: 4\n",
      "      Size: 3.6 GB\n",
      "      Avg shard: 923.0 MB\n",
      "    val:\n",
      "      Items: 3,923\n",
      "      Shards: 1\n",
      "      Size: 494.4 MB\n",
      "      Avg shard: 494.4 MB\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Summary saved to: C:\\Users\\arjya\\Fall 2025\\Systems for ML\\Project 1\\SML\\format-matters\\runs\\20251127-133730\\builds\\summary.csv\n"
     ]
    }
   ],
   "source": [
    "# # Read and display summary\n",
    "# if SUMMARY_CSV.exists() and SUMMARY_CSV.stat().st_size > 0:\n",
    "#     import pandas as pd\n",
    "#     cols = [\n",
    "#     \"stage\", \"dataset\", \"format\", \"variant\", \"split\",\n",
    "#     \"items\", \"bytes_on_disk\", \"num_files\", \"avg_file_size\",\n",
    "#     \"build_wall_s\", \"timestamp\"\n",
    "#     ]\n",
    "#     summary_df = pd.read_csv(SUMMARY_CSV, names=cols, header=None)\n",
    "    \n",
    "#     print(\"\\nBuild Summary:\")\n",
    "#     print(\"=\"*80)\n",
    "    \n",
    "#     for dataset in summary_df['dataset'].unique():\n",
    "#         print(f\"\\n{dataset}:\")\n",
    "#         dataset_df = summary_df[summary_df['dataset'] == dataset]\n",
    "        \n",
    "#         for variant in dataset_df['variant'].unique():\n",
    "#             variant_df = dataset_df[dataset_df['variant'] == variant]\n",
    "#             print(f\"\\n  {variant}:\")\n",
    "            \n",
    "#             for _, row in variant_df.iterrows():\n",
    "#                 print(f\"    {row['split']}:\")\n",
    "#                 print(f\"      Items: {row['items']:,}\")\n",
    "#                 print(f\"      Shards: {row['num_files']}\")\n",
    "#                 print(f\"      Size: {format_bytes(row['bytes_on_disk'])}\")\n",
    "#                 print(f\"      Avg shard: {format_bytes(row['avg_file_size'])}\")\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(f\"\\nSummary saved to: {SUMMARY_CSV}\")\n",
    "# else:\n",
    "#     print(\"No summary data available\")\n",
    "if SUMMARY_CSV.exists() and SUMMARY_CSV.stat().st_size > 0:\n",
    "    import pandas as pd\n",
    "\n",
    "    cols = [\n",
    "        \"stage\", \"dataset\", \"format\", \"variant\", \"split\",\n",
    "        \"items\", \"bytes_on_disk\", \"num_files\", \"avg_file_size\",\n",
    "        \"build_wall_s\", \"timestamp\"\n",
    "    ]\n",
    "\n",
    "    summary_df = pd.read_csv(SUMMARY_CSV, names=cols, header=None)\n",
    "\n",
    "    # Convert all numeric columns safely\n",
    "    numeric_cols = [\"items\", \"bytes_on_disk\", \"num_files\", \"avg_file_size\", \"build_wall_s\"]\n",
    "    summary_df[numeric_cols] = summary_df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    print(\"\\nBuild Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for dataset in summary_df[\"dataset\"].dropna().unique():\n",
    "        print(f\"\\n{dataset}:\")\n",
    "        dataset_df = summary_df[summary_df[\"dataset\"] == dataset]\n",
    "\n",
    "        for variant in dataset_df[\"variant\"].dropna().unique():\n",
    "            print(f\"\\n  {variant}:\")\n",
    "            variant_df = dataset_df[dataset_df[\"variant\"] == variant]\n",
    "\n",
    "            for _, row in variant_df.iterrows():\n",
    "                split = row[\"split\"] if pd.notna(row[\"split\"]) else \"Unknown\"\n",
    "\n",
    "                items = f\"{int(row['items']):,}\" if pd.notna(row[\"items\"]) else \"N/A\"\n",
    "                shards = f\"{int(row['num_files'])}\" if pd.notna(row[\"num_files\"]) else \"N/A\"\n",
    "                size = format_bytes(row[\"bytes_on_disk\"]) if pd.notna(row[\"bytes_on_disk\"]) else \"N/A\"\n",
    "                avg_size = format_bytes(row[\"avg_file_size\"]) if pd.notna(row[\"avg_file_size\"]) else \"N/A\"\n",
    "\n",
    "                print(f\"    {split}:\")\n",
    "                print(f\"      Items: {items}\")\n",
    "                print(f\"      Shards: {shards}\")\n",
    "                print(f\"      Size: {size}\")\n",
    "                print(f\"      Avg shard: {avg_size}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\nSummary saved to: {SUMMARY_CSV}\")\n",
    "else:\n",
    "    print(\"No summary data available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ WebDataset Build Complete\n",
    "\n",
    "**What was created:**\n",
    "- TAR-based shards with configurable sizes\n",
    "- Multiple variants with different shard sizes and compression\n",
    "- Sequential I/O friendly format\n",
    "\n",
    "**Variants built:**\n",
    "- `shard64_none`: 64MB shards, no compression\n",
    "- `shard64_zstd`: 64MB shards, zstd compression\n",
    "- `shard256_none`: 256MB shards, no compression\n",
    "- `shard256_zstd`: 256MB shards, zstd compression\n",
    "- `shard1024_none`: 1024MB shards, no compression\n",
    "- `shard1024_zstd`: 1024MB shards, zstd compression\n",
    "\n",
    "**Output locations:**\n",
    "- `data/built/<dataset>/webdataset/<variant>/*.tar[.zst]`\n",
    "\n",
    "**Next steps:**\n",
    "1. Run `12_loader_webdataset.ipynb` to create the dataloader\n",
    "2. Or continue with other format builders (04-05)\n",
    "3. Then run training experiments (20-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

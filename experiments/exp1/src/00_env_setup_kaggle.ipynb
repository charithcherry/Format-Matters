{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Kaggle Environment Setup (GPU)\n",
    "\n",
    "This notebook sets up the Kaggle GPU environment for the Format Matters project.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Kaggle account with GPU quota\n",
    "- GPU accelerator enabled in notebook settings\n",
    "\n",
    "**Steps:**\n",
    "1. Enable GPU in Kaggle settings\n",
    "2. Install additional dependencies\n",
    "3. Verify GPU availability\n",
    "4. Check system information\n",
    "5. Set up project directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Enable GPU\n",
    "\n",
    "**IMPORTANT**: Before running this notebook:\n",
    "1. Click the **Settings** icon (⚙️) in the top-right\n",
    "2. Under **Accelerator**, select **GPU**\n",
    "3. Click **Save**\n",
    "\n",
    "The notebook will restart with GPU enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Additional Dependencies\n",
    "\n",
    "Kaggle comes with PyTorch pre-installed. We only need to install format-specific libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Install format libraries and utilities\n",
    "!pip install -q webdataset==0.2.86 tfrecord==1.15 lmdb==1.4.1 pyarrow==16.1.0 psutil==5.9.8\n",
    "\n",
    "print(\"\\n✓ Additional dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Configuration:\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"  cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"  GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"  GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"\\n✓ GPU is available and ready!\")\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: GPU not available!\")\n",
    "    print(\"  Please enable GPU in notebook settings (⚙️ → Accelerator → GPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Core Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Required packages\n",
    "required_packages = [\n",
    "    'torch',\n",
    "    'torchvision',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'PIL',  # Pillow\n",
    "    'webdataset',\n",
    "    'tfrecord',\n",
    "    'lmdb',\n",
    "    'pyarrow',\n",
    "    'psutil',\n",
    "    'matplotlib',\n",
    "    'tqdm',\n",
    "]\n",
    "\n",
    "print(\"Checking installed packages:\\n\")\n",
    "all_ok = True\n",
    "\n",
    "for package_name in required_packages:\n",
    "    try:\n",
    "        module = importlib.import_module(package_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"✓ {package_name:15s} {version}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ {package_name:15s} NOT INSTALLED\")\n",
    "        all_ok = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_ok:\n",
    "    print(\"✓ All dependencies available!\")\n",
    "else:\n",
    "    print(\"⚠ Some dependencies missing - re-run installation cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(f\"  OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"  Platform: {platform.platform()}\")\n",
    "print(f\"  Processor: {platform.processor()}\")\n",
    "print(f\"  CPU cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical\")\n",
    "print(f\"  RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"  Python: {platform.python_version()}\")\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
    "print(f\"Available space: {psutil.disk_usage('/kaggle/working').free / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kaggle Directory Structure\n",
    "\n",
    "Kaggle has specific directories:\n",
    "- `/kaggle/input/` - Read-only datasets\n",
    "- `/kaggle/working/` - Read-write workspace (saved with notebook)\n",
    "- `/kaggle/tmp/` - Temporary storage (not saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"Kaggle directories:\\n\")\n",
    "\n",
    "# Check input datasets\n",
    "input_dir = Path('/kaggle/input')\n",
    "if input_dir.exists():\n",
    "    datasets = list(input_dir.iterdir())\n",
    "    print(f\"Input datasets ({len(datasets)}):\")\n",
    "    for ds in datasets[:10]:  # Show first 10\n",
    "        print(f\"  - {ds.name}\")\n",
    "    if len(datasets) > 10:\n",
    "        print(f\"  ... and {len(datasets) - 10} more\")\n",
    "else:\n",
    "    print(\"No input datasets found\")\n",
    "\n",
    "print(f\"\\nWorking directory: /kaggle/working\")\n",
    "print(f\"Temporary directory: /kaggle/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Project Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use /kaggle/working as base\n",
    "base_dir = Path('/kaggle/working/format-matters')\n",
    "\n",
    "# Define directory structure\n",
    "directories = [\n",
    "    base_dir / 'data/raw/cifar10',\n",
    "    base_dir / 'data/raw/imagenet-mini',\n",
    "    base_dir / 'data/built',\n",
    "    base_dir / 'runs',\n",
    "    base_dir / 'notebooks',\n",
    "    base_dir / 'scripts',\n",
    "]\n",
    "\n",
    "print(\"Creating project directories:\\n\")\n",
    "for dir_path in directories:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"  ✓ {dir_path}\")\n",
    "\n",
    "print(\"\\n✓ Directory structure created successfully!\")\n",
    "print(f\"\\nProject root: {base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Basic Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Testing basic functionality:\\n\")\n",
    "\n",
    "# Test PyTorch with GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x = torch.randn(2, 3, 224, 224, device=device)\n",
    "print(f\"✓ PyTorch tensor on {device}: {x.shape}\")\n",
    "\n",
    "# Test torchvision transforms\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "print(f\"✓ Torchvision transforms ready\")\n",
    "\n",
    "# Test numpy\n",
    "arr = np.random.rand(10, 10)\n",
    "print(f\"✓ NumPy array creation: {arr.shape}\")\n",
    "\n",
    "# Test pandas\n",
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "print(f\"✓ Pandas DataFrame: {df.shape}\")\n",
    "\n",
    "# Test PIL\n",
    "img = Image.new('RGB', (100, 100), color='red')\n",
    "print(f\"✓ PIL Image creation: {img.size}\")\n",
    "\n",
    "# Test GPU computation\n",
    "if torch.cuda.is_available():\n",
    "    a = torch.randn(1000, 1000, device='cuda')\n",
    "    b = torch.randn(1000, 1000, device='cuda')\n",
    "    c = torch.matmul(a, b)\n",
    "    print(f\"✓ GPU matrix multiplication: {c.shape}\")\n",
    "\n",
    "print(\"\\n✓ All basic functionality tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Environment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "env_info = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"environment\": \"kaggle\",\n",
    "    \"python_version\": sys.version,\n",
    "    \"pytorch_version\": torch.__version__,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"cuda_version\": torch.version.cuda if torch.cuda.is_available() else None,\n",
    "    \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "    \"gpu_memory_gb\": round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 1) if torch.cuda.is_available() else None,\n",
    "    \"os\": platform.system(),\n",
    "    \"cpu_count\": psutil.cpu_count(logical=True),\n",
    "    \"ram_gb\": round(psutil.virtual_memory().total / (1024**3), 1),\n",
    "    \"disk_free_gb\": round(psutil.disk_usage('/kaggle/working').free / (1024**3), 1),\n",
    "}\n",
    "\n",
    "print(\"Environment Summary:\")\n",
    "print(json.dumps(env_info, indent=2))\n",
    "\n",
    "# Save to file\n",
    "env_file = Path('/kaggle/working/format-matters/runs/env_kaggle.json')\n",
    "env_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "env_file.write_text(json.dumps(env_info, indent=2))\n",
    "print(f\"\\n✓ Environment info saved to: {env_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Dataset Setup Instructions\n",
    "\n",
    "To add datasets to Kaggle:\n",
    "\n",
    "### Option 1: Use Kaggle Datasets\n",
    "1. Find or upload your dataset to Kaggle Datasets\n",
    "2. In this notebook, click **Add Data** (right sidebar)\n",
    "3. Search for and add your dataset\n",
    "4. It will appear under `/kaggle/input/<dataset-name>/`\n",
    "\n",
    "### Option 2: Upload Directly\n",
    "1. Click **Add Data** → **Upload**\n",
    "2. Upload your dataset files\n",
    "3. They will appear under `/kaggle/input/`\n",
    "\n",
    "### Recommended Datasets\n",
    "- **CIFAR-10**: Will be auto-downloaded in `01_prepare_datasets.ipynb`\n",
    "- **ImageNet-mini** or **Tiny-ImageNet-200**: Upload as Kaggle dataset\n",
    "\n",
    "### Copy to Working Directory\n",
    "In `01_prepare_datasets.ipynb`, we'll copy from `/kaggle/input/` to `/kaggle/working/format-matters/data/raw/` so builders can write to `data/built/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Setup Complete!\n",
    "\n",
    "Your Kaggle GPU environment is ready. Next steps:\n",
    "\n",
    "1. **Add datasets**: Use \"Add Data\" to include ImageNet-mini or Tiny-ImageNet-200\n",
    "2. **Prepare datasets**: Run `01_prepare_datasets.ipynb`\n",
    "3. **Build formats**: Run builder notebooks (02-05)\n",
    "4. **Run experiments**: Execute training notebooks (20-21)\n",
    "5. **Analyze results**: Use analysis notebooks (30-31)\n",
    "6. **Download results**: Use `scripts/zip_runs_for_download.ipynb`\n",
    "\n",
    "**Important Notes:**\n",
    "- Kaggle notebooks have a **9-hour runtime limit**\n",
    "- GPU quota is limited - use efficiently\n",
    "- Save important results frequently\n",
    "- Use the zip utility to download results before session ends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}